{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured RerF Demo: Impulse Response\n",
    "We form a two-class classification problem where each data point is 100 timesteps. Class 0 is simply white noise while class 1 is white noise plus an exponentially decaying unit impulse beginning at timestep 20.\n",
    "\n",
    "We test the performance of S-Rerf and a set of other classification algorithms, training each on samples of sizes $n \\in \\{50,100,200,400,1000,2000\\}$, each containing an equal number of data points in each class. The average 0-1 loss is evaluated for each algorithm for each training size using a single test set of size $m=10000$ with an equal number of data points in each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import gc\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, multiprocessing\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "import rerf\n",
    "from rerf.rerfClassifier import rerfClassifier\n",
    "from graspy.plot import heatmap\n",
    "\n",
    "from scipy.stats import bernoulli\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils.load_Xy import *\n",
    "from utils.utils import plot_data\n",
    "\n",
    "gc.enable()\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = np.array([10,50,100,200,400,1000,2000])\n",
    "n0 = int(max(ns) / 2)\n",
    "n1 = n0\n",
    "n_test = 10000\n",
    "\n",
    "X_train,y_train,_ = load_impulse_Xy(n0,n1,ns,seed=0)\n",
    "X_test,y_test,size_dict = load_impulse_Xy(int(n_test/2),int(n_test/2),ns,seed=1)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup for run\n",
    "names = {\"Log. Reg\": \"#a6cee3\", \n",
    "         \"Lin. SVM\":\"#1f78b4\", \n",
    "         \"SVM\":\"#b2df8a\", \n",
    "         \"kNN\": \"#33a02c\", \n",
    "         \"RF\":\"#fb9a99\", \n",
    "         \"MLP\":\"#fdbf6f\", \n",
    "         \"SPORF\":\"#ff7f00\", \n",
    "         \"MF\":\"#e31a1c\",\n",
    "         \"CNN\":\"#cab2d6\"}\n",
    "\n",
    "ncores=40\n",
    "num_runs=3\n",
    "n_est=100\n",
    "\n",
    "classifiers = [\n",
    "    LogisticRegression(random_state=0, n_jobs=ncores, solver='liblinear'),\n",
    "    LinearSVC(),\n",
    "    SVC(C=1.0, kernel='rbf', gamma='auto',random_state=0),\n",
    "    KNeighborsClassifier(3, n_jobs=ncores),\n",
    "    RandomForestClassifier(n_estimators=n_est, max_features='auto', n_jobs=ncores),\n",
    "    MLPClassifier(hidden_layer_sizes=(100, ), random_state=0, max_iter=1000),\n",
    "    rerfClassifier(n_estimators = n_est, projection_matrix = \"RerF\",\n",
    "                    max_features = 'auto', n_jobs = ncores),\n",
    "    rerfClassifier(projection_matrix=\"S-RerF\",\n",
    "                   max_features='auto',\n",
    "                   n_jobs=ncores,\n",
    "                    n_estimators=n_est,\n",
    "                    oob_score=False,\n",
    "                    random_state=0,\n",
    "                    image_height=size_dict['height'],\n",
    "                    image_width=size_dict['width'],\n",
    "                    patch_height_max=1,\n",
    "                    patch_height_min=1,\n",
    "                    patch_width_max=2,\n",
    "                    patch_width_min=1\n",
    "                   )\n",
    "    ]\n",
    "## GSCV params\n",
    "refit = False\n",
    "metric = 'accuracy'\n",
    "cv = 3 # number of splits stratifiedKFold\n",
    "param_grid = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 168/168 [00:41<00:00,  4.01it/s]\n"
    }
   ],
   "source": [
    "# Train each classifier on each dataset size, then test\n",
    "## Prep output file:\n",
    "save_dir = Path('.')\n",
    "write_path = save_dir / 'impulse_results_sklearn.csv'\n",
    "f = open(write_path, 'w+')\n",
    "f.write(\"classifier,n,Lhat,trainTime,testTime,iterate\\n\")\n",
    "f.flush()\n",
    "\n",
    "runList = [(n, clf, run) for n in ns\\\n",
    "                       for clf in zip(classifiers, [key for key in names])\\\n",
    "                       for run in range(num_runs)]\n",
    "\n",
    "for n, clf, iteration in tqdm(runList):\n",
    "        X = X_train[:n]\n",
    "        y = y_train[:n]\n",
    "\n",
    "        trainStartTime = time.time()\n",
    "        clf[0].fit(X, y)\n",
    "        trainEndTime = time.time()\n",
    "        trainTime = trainEndTime - trainStartTime\n",
    "\n",
    "        testStartTime = time.time()\n",
    "        out = clf[0].predict(X_test)\n",
    "        testEndTime = time.time()\n",
    "        testTime = testEndTime - testStartTime\n",
    "\n",
    "        lhat = np.mean(np.not_equal(out, y_test).astype(int))\n",
    "\n",
    "\n",
    "        ####(\"variable,Lhat,trainTime,testTime,iterate\")\n",
    "        f.write(f\"{clf[1]}, {n}, {lhat:2.9f}, {trainTime:2.9f}, {testTime:2.9f}, {iteration}\\n\")\n",
    "        f.flush()\n",
    "\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bite56226f122fe46bfb18dc95209ecfe50"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}